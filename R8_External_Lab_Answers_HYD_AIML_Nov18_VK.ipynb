{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGIsF1ADyJ58"
   },
   "source": [
    "# Transfer Learning CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-n6tVFayGBe"
   },
   "source": [
    "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cq8ejXHJyGYq"
   },
   "source": [
    "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWYbxnBayFUP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 48s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = y_train.reshape(y_train.shape[0])\n",
    "y_test = y_test.reshape(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lt5 = x_train[y_train<5]\n",
    "y_train_lt5 = y_train[y_train<5]\n",
    "x_test_lt5 = x_test[y_test<5]\n",
    "y_test_lt5 = y_test[y_test<5]\n",
    "\n",
    "x_train_gt5 = x_train[y_train>=5]\n",
    "y_train_gt5 = y_train[y_train>=5]\n",
    "x_test_gt5 = x_test[y_test>=5]\n",
    "y_test_gt5 = y_test[y_test>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtCKmQh4yXhT"
   },
   "source": [
    "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN5O2kJ3yYa6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_train_lt5 = pd.get_dummies(y_train_lt5)\n",
    "y_test_lt5 = pd.get_dummies(y_test_lt5)\n",
    "\n",
    "y_train_gt5 = pd.get_dummies(y_train_gt5)\n",
    "y_test_gt5 = pd.get_dummies(y_test_gt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000, 5)\n",
      "(5000, 32, 32, 3)\n",
      "(5000, 5)\n",
      "=============\n",
      "(25000, 32, 32, 3)\n",
      "(25000, 5)\n",
      "(5000, 32, 32, 3)\n",
      "(5000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_lt5.shape)\n",
    "print(y_train_lt5.shape)\n",
    "print(x_test_lt5.shape)\n",
    "print(y_test_lt5.shape)\n",
    "print(\"=============\")\n",
    "print(x_train_gt5.shape)\n",
    "print(y_train_gt5.shape)\n",
    "print(x_test_gt5.shape)\n",
    "print(y_test_gt5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cuOiKWfeybAl"
   },
   "source": [
    "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5HzxNbiiyoBD"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Flatten,BatchNormalization,MaxPooling2D,Dropout, Convolution2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape = (32,32,3)))\n",
    "model.add(Convolution2D(32,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_2 (Batch (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 315,089\n",
      "Trainable params: 315,083\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1124 21:14:57.621248 22596 deprecation_wrapper.py:119] From C:\\Users\\VKE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1124 21:14:57.859333 22596 deprecation.py:323] From C:\\Users\\VKE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "25000/25000 [==============================] - 22s 889us/step - loss: 1.0102 - acc: 0.5968 - val_loss: 0.7835 - val_acc: 0.7066TA: 9s - loss: 1.0911 - acc: 0. - ETA: 8s - loss: 1.0884 - acc - ETA: 8s - loss: 1.0816 - acc: 0.562 - ETA: 8s - loss: 1.080 - ETA: 6s - loss: 1.0658 - a - ETA: 5s  - ETA: 3s - loss: 1.0335 - acc: - ETA: 2s - loss: - ETA: 0s - loss: 1.0175 \n",
      "Epoch 2/30\n",
      "25000/25000 [==============================] - 18s 724us/step - loss: 0.7787 - acc: 0.6965 - val_loss: 0.6807 - val_acc: 0.7378 loss: 0.8950 - acc - ETA: 15s - loss: 0.8991 - acc: 0.64 - ETA: 15s - loss: 0.8976 - ETA - ETA: 14s - loss: 0.8382 - ETA: 14s - loss: 0.8317 - ETA: 12s - loss: 0.82 - E - ETA: 10s  - ETA: 9s - lo - ETA: 8s - loss: 0.8038 - acc: 0.688 - ETA: 8s - loss: 0.8037 - a - ETA: 7s - los - ETA: 6s - loss: 0.7970 - - ETA: 5s - lo - ETA: 1s - loss: 0.7 - ETA: 0s - loss: 0.7793 - acc: 0.6\n",
      "Epoch 3/30\n",
      "25000/25000 [==============================] - 19s 740us/step - loss: 0.6973 - acc: 0.7346 - val_loss: 0.6308 - val_acc: 0.76466s - loss: 0.69 - ETA: 15s - loss: 0.6978 - - ETA: 15s - loss: 0.6952 - acc: 0.73 - ETA: 14s - loss: 0.6971 - acc:  - ETA - ETA - ETA: 12s - lo - ETA: 11s - los - ETA: 9s - loss: 0.6943 - acc:  - ETA: 9s -\n",
      "Epoch 4/30\n",
      "25000/25000 [==============================] - 19s 757us/step - loss: 0.6335 - acc: 0.7580 - val_loss: 0.5827 - val_acc: 0.7812- ETA: 2s - loss:  - ETA: 0s - loss: 0.63\n",
      "Epoch 5/30\n",
      "25000/25000 [==============================] - 19s 768us/step - loss: 0.5799 - acc: 0.7788 - val_loss: 0.5603 - val_acc: 0.78802s - loss: 0.5804 - acc: 0 - ETA: 1s - loss: 0.5817 - a - ETA: 1s - loss: 0.5826 - acc: 0. - ETA: 0s - loss: 0.5818 -  - ETA: 0s - loss: 0.5806 - acc: 0.7\n",
      "Epoch 6/30\n",
      "25000/25000 [==============================] - 20s 786us/step - loss: 0.5361 - acc: 0.7982 - val_loss: 0.5441 - val_acc: 0.79322s - loss: 0.5356 - acc:  - ETA: 12s  - ETA: 11s - loss: 0.53 - ETA - E - ETA: 5s - loss: 0.5304 - acc: 0.799 - ETA: 5s - loss: 0.5303 - acc: 0 - ETA: 4s - loss: 0.5299 - acc: - ETA: 4s -  - ETA: 2s - loss: 0.5349 - acc: 0.798 - ETA: 2s - loss: 0.53 - ETA: 1s - loss: 0.5351 - acc: 0. - ETA: 1s - loss\n",
      "Epoch 7/30\n",
      "25000/25000 [==============================] - 22s 884us/step - loss: 0.5068 - acc: 0.8060 - val_loss: 0.5527 - val_acc: 0.7938\n",
      "Epoch 8/30\n",
      "25000/25000 [==============================] - 23s 910us/step - loss: 0.4710 - acc: 0.8223 - val_loss: 0.5663 - val_acc: 0.7918\n",
      "Epoch 9/30\n",
      "25000/25000 [==============================] - 20s 788us/step - loss: 0.4512 - acc: 0.8313 - val_loss: 0.5217 - val_acc: 0.8064\n",
      "Epoch 10/30\n",
      "25000/25000 [==============================] - 21s 855us/step - loss: 0.4312 - acc: 0.8389 - val_loss: 0.5365 - val_acc: 0.8002\n",
      "Epoch 11/30\n",
      "25000/25000 [==============================] - 20s 803us/step - loss: 0.4067 - acc: 0.8466 - val_loss: 0.5221 - val_acc: 0.8126: 3s - loss: 0.3989 - acc - ETA: 2s - loss: 0.4014 - a - ETA: 1s - loss: - ETA: 0s - loss: 0.4045 \n",
      "Epoch 12/30\n",
      "25000/25000 [==============================] - 20s 820us/step - loss: 0.3870 - acc: 0.8551 - val_loss: 0.5303 - val_acc: 0.8144- ETA: 3s - loss: 0 - ETA: 2s - los - ETA: 1s - loss: 0\n",
      "Epoch 13/30\n",
      "25000/25000 [==============================] - 21s 848us/step - loss: 0.3704 - acc: 0.8604 - val_loss: 0.5467 - val_acc: 0.8142\n",
      "Epoch 14/30\n",
      "25000/25000 [==============================] - 21s 826us/step - loss: 0.3495 - acc: 0.8703 - val_loss: 0.5338 - val_acc: 0.8100\n",
      "Epoch 15/30\n",
      "25000/25000 [==============================] - 20s 808us/step - loss: 0.3354 - acc: 0.8727 - val_loss: 0.5477 - val_acc: 0.8124\n",
      "Epoch 16/30\n",
      "25000/25000 [==============================] - 21s 844us/step - loss: 0.3307 - acc: 0.8753 - val_loss: 0.5215 - val_acc: 0.8198\n",
      "Epoch 17/30\n",
      "25000/25000 [==============================] - 21s 826us/step - loss: 0.3124 - acc: 0.8840 - val_loss: 0.5422 - val_acc: 0.8164\n",
      "Epoch 18/30\n",
      "25000/25000 [==============================] - 21s 856us/step - loss: 0.2984 - acc: 0.8900 - val_loss: 0.5498 - val_acc: 0.8216\n",
      "Epoch 19/30\n",
      "25000/25000 [==============================] - 23s 921us/step - loss: 0.2957 - acc: 0.8883 - val_loss: 0.5553 - val_acc: 0.8162\n",
      "Epoch 20/30\n",
      "25000/25000 [==============================] - 23s 910us/step - loss: 0.2831 - acc: 0.8952 - val_loss: 0.5584 - val_acc: 0.8156\n",
      "Epoch 21/30\n",
      "25000/25000 [==============================] - 24s 956us/step - loss: 0.2738 - acc: 0.8966 - val_loss: 0.5526 - val_acc: 0.8246\n",
      "Epoch 22/30\n",
      "25000/25000 [==============================] - 23s 907us/step - loss: 0.2669 - acc: 0.9021 - val_loss: 0.5490 - val_acc: 0.8246\n",
      "Epoch 23/30\n",
      "25000/25000 [==============================] - 22s 879us/step - loss: 0.2605 - acc: 0.9032 - val_loss: 0.5720 - val_acc: 0.8138\n",
      "Epoch 24/30\n",
      "25000/25000 [==============================] - 22s 886us/step - loss: 0.2572 - acc: 0.9028 - val_loss: 0.5693 - val_acc: 0.8190\n",
      "Epoch 25/30\n",
      "25000/25000 [==============================] - 22s 873us/step - loss: 0.2492 - acc: 0.9074 - val_loss: 0.6022 - val_acc: 0.8158\n",
      "Epoch 26/30\n",
      "25000/25000 [==============================] - 22s 888us/step - loss: 0.2521 - acc: 0.9063 - val_loss: 0.5724 - val_acc: 0.8226\n",
      "Epoch 27/30\n",
      "25000/25000 [==============================] - 23s 901us/step - loss: 0.2428 - acc: 0.9087 - val_loss: 0.5847 - val_acc: 0.8234\n",
      "Epoch 28/30\n",
      "25000/25000 [==============================] - 23s 940us/step - loss: 0.2375 - acc: 0.9145 - val_loss: 0.5624 - val_acc: 0.8260\n",
      "Epoch 29/30\n",
      "25000/25000 [==============================] - 24s 946us/step - loss: 0.2331 - acc: 0.9126 - val_loss: 0.5467 - val_acc: 0.8242\n",
      "Epoch 30/30\n",
      "25000/25000 [==============================] - 24s 942us/step - loss: 0.2245 - acc: 0.9175 - val_loss: 0.5502 - val_acc: 0.8254\n",
      "5000/5000 [==============================] - 1s 242us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5501628074645996, 0.8254]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import adam\n",
    "optimizer = adam(lr = 0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.fit(x_train_lt5,y_train_lt5, validation_data=(x_test_lt5,y_test_lt5), epochs = 30, batch_size= 32) \n",
    "\n",
    "model.evaluate(x_test_lt5,y_test_lt5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woTfNst_ynRG"
   },
   "source": [
    "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_VCDB3Byb1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_2\n",
      "conv2d_3\n",
      "max_pooling2d_3\n",
      "dropout_4\n",
      "conv2d_4\n",
      "max_pooling2d_4\n",
      "dropout_5\n",
      "flatten_2\n",
      "dense_3\n",
      "dropout_6\n",
      "dense_4\n"
     ]
    }
   ],
   "source": [
    "for layers in model.layers:\n",
    "    print(layers.name)\n",
    "    if('dense' not in layers.name):\n",
    "        layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mbatch_normalization_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mconv2d_3\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mmax_pooling2d_3\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdropout_4\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mconv2d_4\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mmax_pooling2d_4\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdropout_5\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mflatten_2\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_3\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n",
      "\u001b[34mdropout_6\u001b[0m\n",
      "\u001b[31mFalse\u001b[0m\n",
      "\u001b[34mdense_4\u001b[0m\n",
      "\u001b[31mTrue\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Module to print colourful statements\n",
    "from termcolor import colored\n",
    "\n",
    "#Check which layers have been frozen \n",
    "for layer in model.layers:\n",
    "  print (colored(layer.name, 'blue'))\n",
    "  print (colored(layer.trainable, 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-uUPqWpyeyX"
   },
   "source": [
    "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
    "Achieve an accuracy of more than 85% on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szHjJgDvyfCt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 11s 434us/step - loss: 1.2838 - acc: 0.5826 - val_loss: 0.6097 - val_acc: 0.7788\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 10s 416us/step - loss: 0.6788 - acc: 0.7541 - val_loss: 0.5156 - val_acc: 0.8164\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 11s 425us/step - loss: 0.5826 - acc: 0.7900 - val_loss: 0.4755 - val_acc: 0.8326\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 11s 438us/step - loss: 0.5213 - acc: 0.8114 - val_loss: 0.4334 - val_acc: 0.8480\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 11s 433us/step - loss: 0.4686 - acc: 0.8310 - val_loss: 0.4200 - val_acc: 0.8514\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 10s 418us/step - loss: 0.4382 - acc: 0.8412 - val_loss: 0.4056 - val_acc: 0.8608\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 11s 420us/step - loss: 0.4051 - acc: 0.8538 - val_loss: 0.3947 - val_acc: 0.8628\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 11s 421us/step - loss: 0.3855 - acc: 0.8600 - val_loss: 0.3890 - val_acc: 0.8644\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 10s 413us/step - loss: 0.3625 - acc: 0.8693 - val_loss: 0.3822 - val_acc: 0.8642\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 10s 410us/step - loss: 0.3468 - acc: 0.8744 - val_loss: 0.3838 - val_acc: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b17a364a8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import adam\n",
    "optimizer = adam(lr = 0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.fit(x_train_gt5,y_train_gt5,validation_data=(x_test_gt5,y_test_gt5), epochs = 10, batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 215us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3838233545780182, 0.8682]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_gt5,y_test_gt5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU-HwvIdH0M-"
   },
   "source": [
    "## Sentiment analysis <br> \n",
    "\n",
    "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
    "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAQDiZHRH0M_"
   },
   "source": [
    "### 6. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eXGIe-SH0NA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./tweets.csv', encoding = \"ISO-8859-1\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CWeWe1eJH0NF",
    "outputId": "4b149292-457b-44f8-988c-cb40676eff65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7kX-WoJDH0NV",
    "outputId": "825e58ae-0d18-4d90-9317-64854366c048"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3182</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>918</td>\n",
       "      <td>2672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet_text  \\\n",
       "count                                                3191   \n",
       "unique                                               3182   \n",
       "top     RT @mention Marissa Mayer: Google Will Connect...   \n",
       "freq                                                    3   \n",
       "\n",
       "       emotion_in_tweet_is_directed_at  \\\n",
       "count                             3191   \n",
       "unique                               9   \n",
       "top                               iPad   \n",
       "freq                               918   \n",
       "\n",
       "       is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "count                                                3191  \n",
       "unique                                                  2  \n",
       "top                                      Positive emotion  \n",
       "freq                                                 2672  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGWB3P2WH0NY"
   },
   "source": [
    "### Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdgA_8N2H0NY"
   },
   "outputs": [],
   "source": [
    "data = data[(data['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (data['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_Jlu-reIH0Na",
    "outputId": "6eeb9100-56bd-48d5-b0e6-ef758e650ded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3191, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SotCRvkDH0Nf"
   },
   "source": [
    "### 7. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
    "\n",
    "#### Use `vect` as the variable name for initialising CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcbkY4sgH0Ng"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(data['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyXtZGr-H0Nl"
   },
   "outputs": [],
   "source": [
    "doc_matrix = cv.transform(data.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4LUM-XPH0Nn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "doc_matrix1 = doc_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIdZYxJtH0Nq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3191, 5648)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_matrix1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pxd5fSHH0Nt"
   },
   "source": [
    "### 8. Find number of different words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1DQ2LdNH0Nu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 79)\t1\n",
      "  (0, 227)\t1\n",
      "  (0, 417)\t2\n",
      "  (0, 1290)\t1\n",
      "  (0, 2286)\t1\n",
      "  (0, 2426)\t1\n",
      "  (0, 2641)\t1\n",
      "  (0, 2663)\t1\n",
      "  (0, 3304)\t1\n",
      "  (0, 3706)\t1\n",
      "  (0, 4145)\t1\n",
      "  (0, 4619)\t1\n",
      "  (0, 4772)\t1\n",
      "  (0, 5014)\t1\n",
      "  (0, 5144)\t1\n",
      "  (0, 5230)\t1\n",
      "  (0, 5373)\t1\n",
      "  (0, 5416)\t1\n",
      "  (1, 152)\t1\n",
      "  (1, 281)\t1\n",
      "  (1, 347)\t1\n",
      "  (1, 367)\t1\n",
      "  (1, 417)\t1\n",
      "  (1, 475)\t1\n",
      "  (1, 1351)\t1\n",
      "  :\t:\n",
      "  (3189, 286)\t1\n",
      "  (3189, 302)\t2\n",
      "  (3189, 347)\t1\n",
      "  (3189, 798)\t1\n",
      "  (3189, 800)\t1\n",
      "  (3189, 1816)\t1\n",
      "  (3189, 1936)\t2\n",
      "  (3189, 2275)\t1\n",
      "  (3189, 2486)\t1\n",
      "  (3189, 2631)\t1\n",
      "  (3189, 2641)\t1\n",
      "  (3189, 2663)\t1\n",
      "  (3189, 3209)\t1\n",
      "  (3189, 3280)\t1\n",
      "  (3189, 4203)\t1\n",
      "  (3189, 4595)\t1\n",
      "  (3189, 4710)\t1\n",
      "  (3189, 4772)\t1\n",
      "  (3189, 4784)\t1\n",
      "  (3189, 5247)\t1\n",
      "  (3189, 5277)\t1\n",
      "  (3190, 1699)\t1\n",
      "  (3190, 2631)\t1\n",
      "  (3190, 2909)\t1\n",
      "  (3190, 4772)\t1\n"
     ]
    }
   ],
   "source": [
    "print(doc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwtgjTBeH0Ny"
   },
   "source": [
    "#### Tip: To see all available functions for an Object use dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1258
    },
    "colab_type": "code",
    "id": "2n_iCcTNH0N0",
    "outputId": "8ed6e65b-2afa-410d-9901-bc1dfa1884a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_char_ngrams',\n",
       " '_char_wb_ngrams',\n",
       " '_check_stop_words_consistency',\n",
       " '_check_vocabulary',\n",
       " '_count_vocab',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_limit_features',\n",
       " '_more_tags',\n",
       " '_sort_features',\n",
       " '_stop_words_id',\n",
       " '_validate_custom_analyzer',\n",
       " '_validate_params',\n",
       " '_validate_vocabulary',\n",
       " '_white_spaces',\n",
       " '_word_ngrams',\n",
       " 'analyzer',\n",
       " 'binary',\n",
       " 'build_analyzer',\n",
       " 'build_preprocessor',\n",
       " 'build_tokenizer',\n",
       " 'decode',\n",
       " 'decode_error',\n",
       " 'dtype',\n",
       " 'encoding',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'fixed_vocabulary_',\n",
       " 'get_feature_names',\n",
       " 'get_params',\n",
       " 'get_stop_words',\n",
       " 'input',\n",
       " 'inverse_transform',\n",
       " 'lowercase',\n",
       " 'max_df',\n",
       " 'max_features',\n",
       " 'min_df',\n",
       " 'ngram_range',\n",
       " 'preprocessor',\n",
       " 'set_params',\n",
       " 'stop_words',\n",
       " 'stop_words_',\n",
       " 'strip_accents',\n",
       " 'token_pattern',\n",
       " 'tokenizer',\n",
       " 'transform',\n",
       " 'vocabulary',\n",
       " 'vocabulary_']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShA6D8jKH0N5"
   },
   "source": [
    "### Find out how many Positive and Negative emotions are there.\n",
    "\n",
    "Hint: Use value_counts on that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "q7LAl5pzH0N6",
    "outputId": "cae0db0f-9918-404d-caab-4a67fc6810bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion    2672\n",
       "Negative emotion     519\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['is_there_an_emotion_directed_at_a_brand_or_product'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUvgj0FoH0N9"
   },
   "source": [
    "###  Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'label'\n",
    "\n",
    "Hint: use map on that column and give labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YftKwFv7H0N9"
   },
   "outputs": [],
   "source": [
    "data['label'] = data.is_there_an_emotion_directed_at_a_brand_or_product.map({'Positive emotion':1, 'Negative emotion':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### 9. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNkwrGgEH0OA"
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = data['tweet_text']\n",
    "y = data['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5nlCuaaH0OD"
   },
   "source": [
    "## 10. **Predicting the sentiment:**\n",
    "\n",
    "\n",
    "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AbVYssaH0OE"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "# create document-term matrices\n",
    "x_train_dtm = vect.fit_transform(x_train)\n",
    "x_test_dtm = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2393, 4919)\n",
      "(798, 4919)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_dtm.shape)\n",
    "print(x_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  4919\n"
     ]
    }
   ],
   "source": [
    "print('Features: ', x_train_dtm.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8471177944862155\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(x_test_dtm)\n",
    "print(accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sw-0B33tH0Ox"
   },
   "source": [
    "## 11. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okCTOs1TH0Oy"
   },
   "outputs": [],
   "source": [
    "def tokenize_test(vect):\n",
    "    x_train_dtm = vect.fit_transform(x_train)\n",
    "    print('Features: ', x_train_dtm.shape[1])\n",
    "    x_test_dtm = vect.transform(x_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(x_test_dtm)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxZ8jfPEH0O0"
   },
   "source": [
    "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kdCyAN_IH0O0",
    "outputId": "403c7b75-49fc-477b-b572-ea4e3ee94153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  24855\n",
      "Accuracy:  0.8558897243107769\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axepytmgH0O4"
   },
   "source": [
    "### 12. Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HToGkq7vH0O4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  4681\n",
      "Accuracy:  0.8533834586466166\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOIlJRxoH0O7"
   },
   "source": [
    "### 13. Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fUhff-oH0O8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  300\n",
      "Accuracy:  0.8107769423558897\n"
     ]
    }
   ],
   "source": [
    "# remove English stop words and only keep 100 features\n",
    "vect = CountVectorizer(stop_words='english', max_features=300)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2KZNWVkH0PA"
   },
   "source": [
    "### 14. Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3v9XD082H0PB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  15000\n",
      "Accuracy:  0.8533834586466166\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and limit the number of features\n",
    "vect = CountVectorizer(ngram_range=(1, 2), max_features=15000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "We3JK_SRH0PO"
   },
   "source": [
    "### 15. Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUHrfDCyH0PP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  7764\n",
      "Accuracy:  0.8583959899749374\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams, and only include terms that appear at least 2 times\n",
    "vect = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R8_External_Lab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
